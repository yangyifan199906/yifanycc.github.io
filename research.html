<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title></title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Yifan Yang</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="research.html" class="current">Research</a></div>
<div class="menu-item"><a href="cv_4.pdf">CV</a></div>
</td>
<td id="layout-content">
<p><br /></p>
<h3>Online Convex Optimization  </h3>
<p>In the context of Online Convex Optimization, the expert select a decision <img class="eq" src="eqs/5999452984665080558-130.png" alt="x_t" style="vertical-align: -4px" /> and get a loss   
<img class="eq" src="eqs/8645826986312865835-130.png" alt="f_t(x_t)" style="vertical-align: -5px" /> with respect to the loss function <img class="eq" src="eqs/1823459540876059346-130.png" alt="f_t(cdot)" style="vertical-align: -5px" /> at each round. The aim of the Online Convex Optimization algorithm is to minimize the total loss over time <img class="eq" src="eqs/4113005419970972680-130.png" alt="[1,T]" style="vertical-align: -5px" />. <br /><br />
I'm interested in plenty of OCO algorithms, with a focus on the OCO algorithm with constraints.</p>
<h3>Multi-armed Bandits</h3>
<p>In probability theory, the multi-armed bandit problem (sometimes called the K or N-armed bandit problem) is a problem in which a fixed limited set of resources must be allocated between competing (alternative) choices in a way that maximizes their expected gain, when each choice's properties are only partially known at the time of allocation, and may become better understood as time passes or by allocating resources to the choice.<br /><br />
My research work focus on the Bandits algorithm with stochastic setting, where each arm of the Bandits follow a special distribution</p>
</td>
</tr>
</table>
</body>
</html>
